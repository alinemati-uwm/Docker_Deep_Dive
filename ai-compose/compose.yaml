volumes:
  model_data:

networks:
  internal:

services:
    frontend:
      image: nigelpoulton/ddd-book:ai-fe
#     build: ./frontend
      command: npm run start
      networks:
        - internal
      ports:
        - target: 3000
          published: 3000
      environment:
        - PORT=3000
        - HOST=0.0.0.0
      depends_on:
        - backend

    backend:
      image: nigelpoulton/ddd-book:ai-be
#     build: ./backend
      networks:
        - internal
      ports:
        - target: 8000
          published: 8000
      environment:
        - MODEL_HOST=http://model:11434
      depends_on:
        model:
          condition: service_healthy
  
    model:
#     image: nigelpoulton/ddd-book:ai-model
      build: ./model
      networks:
        - internal
      ports:
        - published: 11434
          target: 11434
      volumes:
        - type: volume
          source: model_data
          target: /root/.ollama
      environment: 
        - MODEL=${MODEL:-mistral:latest} 
      healthcheck:
        test: ["CMD-SHELL", "curl -s http://localhost:11434/api/tags | jq -e \".models[] | select(.name == \\\"${MODEL:-mistral:latest}\\\")\" > /dev/null"]
        interval: 10s
        timeout: 5s
        retries: 50
        start_period: 900s
      deploy:
        resources:
          limits:
            memory: 8G
